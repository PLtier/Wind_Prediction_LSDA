{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "# Data Pipelines & Data Analytics Life Cycle\n",
    "# Forecasting the Wind Power Production in Orkney"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment and Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the environment with `venv`\n",
    "\n",
    "It is always recommended to create a new environment for any new project to avoid dependency issues and keep a clean working space. \n",
    "\n",
    "Step 1: Create a virtual environment in your project directory:\n",
    "\n",
    "python3 -m venv .venv\n",
    "\n",
    "\n",
    "Step 2: Activate the virtual environment:  \n",
    "For Linux/Mac:  \n",
    "source .venv/bin/activate  \n",
    "\n",
    "\n",
    "For Windows:  \n",
    ".venv\\Scripts\\activate  \n",
    "\n",
    "\n",
    "Step 3: Install the influxdb and MLFlow libraries using requirements.txt from https://github.itu.dk/Large-Scale-Data-Analysis-2025/python_env\n",
    "\n",
    "pip install -r requirements.txt\n",
    "\n",
    "Once your environment is set up and dependencies are installed, you are ready to proceed with your project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You absolutely need these\n",
    "from influxdb import InfluxDBClient\n",
    "import mlflow\n",
    "\n",
    "# You will probably need these\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# This are for example purposes. You may discard them if you don't use them.\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from mlflow.models import infer_signature\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "### TODO -> HERE YOU CAN ADD ANY OTHER LIBRARIES YOU MAY NEED ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data with InfluxDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in an [InfluxDB](https://www.influxdata.com/), which is a non-relational time-series database. InfluxDB can be queried using [InfluxQL](https://docs.influxdata.com/influxdb/v1.8/query_language/spec/), a \"SQL-like\" query language for time-series data. InfluxDB does not have tables with rows and columns, instead data is stored in measurements with fields and tags. <br><br>\n",
    "**NOTE:** <em>You don't need to know much about InfluxDB syntax, but if you are interested, feel free to browse around the [documentation](https://docs.influxdata.com/).</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this assignment is stored in a database, with one table for the weather data and another for the power generation data. To do this, we first need to create an instance of the InfluxDB Client, that will allow us to query the needed data. Let's see how this is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the needed parameters to connect to the database\n",
    "### THIS SHOULD NOT BE CHANGED ###\n",
    "settings = {\n",
    "    'host': 'influxus.itu.dk',\n",
    "    'port': 8086,\n",
    "    'username': 'lsda',\n",
    "    'password': 'icanonlyread'\n",
    "    }\n",
    "\n",
    "# Create an InfluxDB Client instance and select the orkney database\n",
    "### YOU DON'T NEED TO CHANGE ANYTHING HERE ###\n",
    "client = InfluxDBClient(host=settings['host'], port=settings['port'], username=settings['username'], password=settings['password'])\n",
    "client.switch_database('orkney')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained before, InfluxDB uses InfluxQL, a \"SQL-like\" syntax. We will use this to select the data we need from the correspondant tables, using our client instance. Then we can use an auxiliary function to convert the resulting set from the query into a Pandas Dataframe, making it easier to work with.<br><br>\n",
    "**NOTE:** <em>If you are curious to see how the resulting set from InfluxDB looks like, you can avoid using this function and printing the result.</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to tranform the InfluxDB resulting set into a Dataframe\n",
    "### YOU DON'T NEED TO CHANGE ANYTHING HERE ###\n",
    "def set_to_dataframe(resulting_set):\n",
    "    \n",
    "    values = resulting_set.raw[\"series\"][0][\"values\"]\n",
    "    columns = resulting_set.raw[\"series\"][0][\"columns\"]\n",
    "    df = pd.DataFrame(values, columns=columns).set_index(\"time\")\n",
    "    df.index = pd.to_datetime(df.index) # Convert to datetime-index\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to retrieve the data.<br><br>\n",
    "Let's suppose we want the power generation and wind data from the last 90 days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 90 # -> You can change this to get any other range of days\n",
    "\n",
    "### YOU DON'T NEED TO CHANGE ANYTHING HERE ###\n",
    "power_set = client.query(\n",
    "    \"SELECT * FROM Generation where time > now()-\"+str(days)+\"d\"\n",
    "    ) # Query written in InfluxQL. We are retrieving all generation data from 90 days back.\n",
    "\n",
    "# Get the last 90 days of weather forecasts with the shortest lead time\n",
    "wind_set  = client.query(\n",
    "    \"SELECT * FROM MetForecasts where time > now()-\"+str(days)+\"d and time <= now() and Lead_hours = '1'\"\n",
    "    ) # Query written in InfluxQL. We are retrieving all weather forecast data from 90 days back and with 1 lead hour.\n",
    "\n",
    "power_df = set_to_dataframe(power_set)\n",
    "wind_df = set_to_dataframe(wind_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"2\">**NOTE:** <em>You don't need to change the query syntax, but it is useful if you try to make sense out of it.</em> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the resulting dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** <em>This table contains three columns, but closer inspection will reveal a very straigh relationship between those three. Can you spot that?<br>\n",
    "We are clearly interested in the total power generation, regardless of the source type.</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** <em>This table contains four columns, but lead hours and source time are irrelevant here. Can you think why?</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** <em>Look at the table's index. Do both data sources contain the same intervals? And if not, what problems could arise when merging the data?</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two dataframes, one with weather forecast and one with power generation. To do some analysis on the relationship between these two datasets, it might be useful to join (and align) the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the data\n",
    "joined_dfs = power_df.join(wind_df, how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining the two datasets with an inner join means keeping only those records that match their index. Although this will work, you may notice that most of our data is discarded due to the unmatching time intervals. You may want to explore other possible ways to merge the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO -> JOIN THE TWO DATASETS ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the data: EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be also useful to plot our datasets to see what relationships they might hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subplots\n",
    "fig, ax = plt.subplots(1,3, figsize=(25,4))\n",
    "\n",
    "# Speed and Power for the last 7 days\n",
    "ax[0].plot(joined_dfs[\"Speed\"].tail(int(7*24/3)), label=\"Speed\", color=\"blue\") # Since the datasets are joined every three hours, we need the last 7 days times 24 hours diveded by 3 hours\n",
    "ax[0].plot(joined_dfs[\"Total\"].tail(int(7*24/3)), label=\"Power\", color=\"tab:red\") # Since the datasets are joined every three hours, we need the last 7 days times 24 hours diveded by 3 hours\n",
    "ax[0].set_title(\"Windspeed & Power Generation over last 7 days\")\n",
    "ax[0].set_xlabel(\"Time\")\n",
    "ax[0].tick_params(axis='x', labelrotation = 45)\n",
    "ax[0].set_ylabel(\"Windspeed [m/s], Power [MW]\")\n",
    "ax[0].legend()\n",
    "\n",
    "# Speed vs Total (Power Curve nature)\n",
    "ax[1].scatter(joined_dfs[\"Speed\"], joined_dfs[\"Total\"])\n",
    "power_curve = joined_dfs.groupby(\"Speed\").median(numeric_only=True)[\"Total\"]\n",
    "ax[1].plot(power_curve.index, power_curve.values, \"k:\", label=\"Power Curve\")\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"Windspeed vs Power\")\n",
    "ax[1].set_ylabel(\"Power [MW]\")\n",
    "ax[1].set_xlabel(\"Windspeed [m/s]\")\n",
    "\n",
    "# Speed and Power per Wind Direction\n",
    "wind_grouped_by_direction = joined_dfs.groupby(\"Direction\").mean(numeric_only=True).reset_index()\n",
    "bar_width = 0.5\n",
    "x = np.arange(len(wind_grouped_by_direction.index))\n",
    "\n",
    "ax[2].bar(x, wind_grouped_by_direction.Total, width=0.5, label=\"Power\", color=\"tab:red\")\n",
    "ax[2].bar(x + bar_width, wind_grouped_by_direction.Speed, width=0.5, label=\"Speed\", color=\"blue\")\n",
    "ax[2].legend()\n",
    "ax[2].set_xticks(x)\n",
    "ax[2].set_xticklabels(wind_grouped_by_direction.Direction)\n",
    "ax[2].tick_params(axis='x', labelrotation = 45)\n",
    "ax[2].set_title(\"Speed and Power per Direction\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** <em>These plots should already give us an intuition of the different relationships between features. It seems clear that there is a positive relationship between the wind speed and the power generation from the turbines, as we obviously suspected. But that relationship is not completely linear. Can you spot that? Finally, it seems like the power generation also depends of where the winds is coming from. Maybe this could also be a useful feature.</em> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plot the relationship between wind speed and power generation we have performed a very simple join with the two datasets. But since the intervals are not the same, a lot of data is discarded (<em>can you spot where in the code this happens?</em>). You may want to explore other ways to merge the data sources to minimize the loss of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO -> DO SOME EXTRA EDA ON THE DATA ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Pipeline and data transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, we need to construct the pipeline to process this data and pass it to our Machine Learning model. For this, you may find useful the Pipeline class from Scikit-Learn.\n",
    "\n",
    "This class applies a list of transforms to your data, and pass the final state to an estimator (your model). Intermediate steps of the pipeline must be ‘transforms’, that is, they must implement fit and transform methods. The final estimator only needs to implement fit. \n",
    "\n",
    "The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. For this, it enables setting parameters of the various steps using their names and the parameter name separated by a '__'. \n",
    "\n",
    "You can find more information about Scikit-Learn's Pipeline [here](https://scikit-learn.org/stable/modules/compose.html#pipeline)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A very basic pipeline\n",
    "pipeline_example = Pipeline([\n",
    "    # Transformations\n",
    "    (\"Scaler\", StandardScaler()),\n",
    "    # Estimator\n",
    "    (\"Linear Regression\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO -> CREATE YOUR OWN PIPELINE ###\n",
    "# Create your pipeline with the desired transformers\n",
    "pipeline = Pipeline([\n",
    "\n",
    "    # Transformer 1\n",
    "    # Transformer 2\n",
    "    # ...\n",
    "    # Final estimator\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a preprocessing pipeline ready, along with the final estimator, you may want to know how well your model performs. Choose the method you prefer, with special attention to the selected metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select our feature variables and our target variable.\n",
    "joined_dfs = power_df.join(wind_df).dropna()\n",
    "\n",
    "X = joined_dfs[\"Speed\"].values.reshape(-1,1)\n",
    "y = joined_dfs[\"Total\"].values.reshape(-1,1)\n",
    "\n",
    "# Split the data so we can test how well our model performs in unseen data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) # -> You might want to use another split method\n",
    "\n",
    "# Train our model\n",
    "pipeline_example.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model, using MAE as a metric\n",
    "mae = mean_absolute_error(pipeline_example.predict(X_test), y_test)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HINTS:** <em>Pay special attention to this type of data: We are dealing with Time series data (i.e. data that is recorded over consistent intervals of time). It might be a good idea not to **randomly** split the data, since it wouldn't respect the temporal order and may cause data-leakage, unintentionally inferring the trend of future samples.</em> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your preferred method to evaluate your model\n",
    "### TODO -> SPLIT THE DATA INTO TRAIN AND TEST SETS, AND EVALUATE YOUR MODEL ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Tracking your experiments with MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a working model with a certain accuracy. But wouldn't it be better to try different parameters and different models before deciding for one? <br><br>\n",
    "This is exactly what we will do using the MLFlow library. MLflow is an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry. This will allow us for easy comparison of all our model experiments. <br>\n",
    "\n",
    "**NOTE:**<em> Don't forget to check the [MLFlow documentation](https://mlflow.org/docs/latest/index.html) to learn more about the library.</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using MLFlow locally to log our experiments, we need to start a \"local server\". We can do this easily by running the following in our command line interface:\n",
    "\n",
    "```\n",
    "mlflow server\n",
    "```\n",
    "\n",
    "For example, using PowerShell, it should look like this:\n",
    "\n",
    "![MLFlow Server](https://github.com/ginofazzi/testing/raw/0d3ffce58ee12f6d1c86b6a3c2ac628314e7b82e/mlflow_server.png)\n",
    "\n",
    "In this example, we can see that the server is located at our localhost 127.0.0.1, port 5000. We will use this information to indicate MLFlow where to save our experiment details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start an MLflow run\n",
    "mlflow.sklearn.autolog() # This is to help us track scikit learn metrics.\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\") # We set the MLFlow UI to display in our local host.\n",
    "\n",
    "# Set the experiment and run name\n",
    "experiment_name = \"LinearRegression-Example\" # I suggest using a different experiment for each model\n",
    "run_name = \"Simple_regression\" # I suggest using a different run name for each tried parameter\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    \n",
    "    # Train our model\n",
    "    pipeline_example.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model, using MAE as a metric\n",
    "    predictions = pipeline_example.predict(X_test)\n",
    "    mae = mean_absolute_error(predictions, y_test)\n",
    "\n",
    "    mlflow.log_metric(\"MAE\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO -> SET YOUR OWN EXPERIMENT SETUP ###\n",
    "\"\"\"\n",
    "Here, you may want to stop and think what is the best way to iterate(!) through all the models and experiments you want to try.\n",
    "Instead of running your code everytime you want to change something, you could try to list all your desired experiments and\n",
    "run them all sequentially in one go (gridsearch style).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have run our experiment(s), trying different pre-processing steps, models and parameters. To easily compare the results from our experiments, we can use the MLFlow interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been logging our experiments in our local server. We can access the UI by opening the localhost address in any browser. When opening the server in the browser, we should see something like this:\n",
    "\n",
    "![MLFlow UI](https://github.com/ginofazzi/testing/raw/0d3ffce58ee12f6d1c86b6a3c2ac628314e7b82e/MLFLowUI.png)\n",
    "\n",
    "In this example, we can see the list of all our experiments in the left, and for each experiment a table with all the different runs.\n",
    "\n",
    "**NOTE:**<em> This example contains only one run for the experiment. When logging multiple runs with different parameters/metrics, you will be able to easily compare them using the \"Chart View\". Make sure to try this out.</em>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have tried many different models with different parameters, we might want to save the best one. To do this, we can use again the UI:\n",
    "\n",
    "1. In the Experiments list, select the model you want to save. In the Table view, select the version of that model (Run name).\n",
    "2. On the left, you will see all the experiment's run details (Parameters, metrics, and ML Project files). Click on \"Register Model\".\n",
    "3. Now, on the \"Models\" tab, you will be able to see your saved model.\n",
    "\n",
    "![MLFlow save model](https://github.com/ginofazzi/testing/raw/0d3ffce58ee12f6d1c86b6a3c2ac628314e7b82e/MLFLow-save_model-1.png)\n",
    "\n",
    "In case of doubt, you can check the documentation [HERE](https://mlflow.org/docs/latest/model-registry.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Using a saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have saved our best model, we might want to use it for future predictions. We can retrieve the weather forecasts for the next days, and make predictions of power generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need the new forecast data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all future forecasts regardless of lead time\n",
    "forecasts  = client.query(\n",
    "    \"SELECT * FROM MetForecasts where time > now()\") # Query written in InfluxQL\n",
    "\n",
    "# Transform the result set into a dataframe\n",
    "forecasts = set_to_dataframe(forecasts)\n",
    "\n",
    "# Limit to only the newest source time, so we have the latest forecast only\n",
    "newest_forecasts = forecasts.loc[forecasts[\"Source_time\"] == forecasts[\"Source_time\"].max()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can retrieve any saved model and use it to predict on the new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model details\n",
    "model_name = \"LinearRegression-Example\"\n",
    "model_version = 1\n",
    "\n",
    "# Use MLFlow to load the saved model\n",
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
    "\n",
    "# Use the saved model to predict the power generation\n",
    "predictions = model.predict(newest_forecasts[\"Speed\"])\n",
    "\n",
    "# We can transform the predictions array to a Pandas DataFrame\n",
    "predictions = pd.DataFrame(predictions, index=newest_forecasts.index, columns=[\"Power\"])\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain your model and keep the best one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we now how to retrieve saved models, it might be a good idea to validate our models troughout time, with new data, and keep the best one every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO -> INSERT YOUR CODE HERE ###\n",
    "\"\"\"\n",
    "You might want to think how to systematically test your model with new data, \n",
    "compare with the metrics of the best saved model, and update your model if \n",
    "necessary. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Deploying your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have trained several models and saved the best for predictions. But we have been working locally. Often times, we will want to deploy our model in such a way that other people can take advantage of it, by sending a request with data and getting back predictions. To do this, we need to create an endopoint for our model to receive data. This is done through deployment of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deploy our model, we first need to serve the model. Serving a model refers to the process of making a trained machine learning model available to receive input data and provide predictions or inferences based on that data. In other words, when you serve a model, you set it up in a way that it can be queried with new data, and it will produce predictions or outputs based on the patterns it learned during training.\n",
    "\n",
    "Serving a model is a critical step in the machine learning lifecycle, as it allows you to leverage the model's predictive capabilities in real-world applications. When a model is served, it becomes accessible to applications, websites, or other systems that need to utilize its predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deploy your model, follow section 3.3 from the Assignment PDF. If you want to learn how to deploy models from the Jupyter Notebook, try out the tutorial notebook at examples/sklearn_elasticnet_wine/train.ipynb. You can find it on the [MLFlow Tutorial](https://mlflow.org/docs/latest/tutorials-and-examples/tutorial.html). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
